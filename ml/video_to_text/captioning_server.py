from transformers import AutoModelForVision2Seq, AutoTokenizer, AutoImageProcessor, LogitsProcessor
import torch
import json
import numpy as np
import torchvision
import torchvision.io
import math
from flask import Flask, request, jsonify
from scene_detect import scene_detect
import os
from flasgger import Swagger
import logging
import hashlib

CACHE_DIR = "json_cached"
model_name_or_path = "Salesforce/xgen-mm-vid-phi3-mini-r-v1.5-128tokens-8frames"
model = AutoModelForVision2Seq.from_pretrained(model_name_or_path, trust_remote_code=True)
tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=True, use_fast=False, legacy=False)
image_processor = AutoImageProcessor.from_pretrained(model_name_or_path, trust_remote_code=True)
tokenizer = model.update_special_tokens(tokenizer)

model = model.to('cuda')
model.eval()
tokenizer.padding_side = "left"
tokenizer.eos_token = "<|end|>"

app = Flask(__name__)
swagger = Swagger(app)

def get_file_hash(video_file):
    """íŒŒì¼ ë‚´ìš©ì„ SHA-256 í•´ì‹œë¡œ ë³€í™˜"""
    hasher = hashlib.sha256()
    video_file.seek(0)  # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ì´ë™
    while chunk := video_file.read(8192):  # 8KBì”© ì½ê¸°
        hasher.update(chunk)
    video_file.seek(0)  # ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ ì´ë™ (ì¤‘ìš”!)
    return hasher.hexdigest()

def sample_frames(vframes, num_frames):
    print('len vframe: ', len(vframes), 'num_frames: ', num_frames)
    if len(vframes) < num_frames:
        frame_indice = [i for i in range(len(vframes))]
    else:
        frame_indice = np.linspace(int(num_frames/2), len(vframes) - int(num_frames/2), num_frames, dtype=int)
    print(frame_indice)
    video = vframes[frame_indice]
    video_list = []
    for i in range(len(video)):
        video_list.append(torchvision.transforms.functional.to_pil_image(video[i]))

    return video_list

def generate(messages, images):
    image_sizes = [image.size for image in images]
    image_tensor = [image_processor([img])["pixel_values"].to(model.device, dtype=torch.float32) for img in images]

    image_tensor = torch.stack(image_tensor, dim=1)
    image_tensor = image_tensor.squeeze(2)
    inputs = {"pixel_values": image_tensor}

    full_conv = "<|system|>\nA chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.<|end|>\n"
    for msg in messages:
        msg_str = "<|{role}|>\n{content}<|end|>\n".format(
            role=msg["role"], content=msg["content"]
        )
        full_conv += msg_str

    full_conv += "<|assistant|>\n"
    print(full_conv)
    language_inputs = tokenizer([full_conv], return_tensors="pt")
    for name, value in language_inputs.items():
        language_inputs[name] = value.to(model.device)
    inputs.update(language_inputs)

    with torch.inference_mode():
        generated_text = model.generate(
            **inputs,
            image_size=[image_sizes],
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
            temperature=1.0,
            do_sample=False,
            max_new_tokens=1024,
            top_p=0.9,
            num_beams=5,
            no_repeat_ngram_size=3,
        )

    outputs = (
        tokenizer.decode(generated_text[0], skip_special_tokens=True)
        .split("<|end|>")[0]
        .strip()
    )
    return outputs

def predict(vframes, num_frames=8):
    total_frames = len(vframes)
    images = sample_frames(vframes, num_frames)
    print('image length :', len(images))
    prompt = ""
    prompt = prompt + "<image>\n"
    prompt = prompt + "For each scene in this video, create a caption that describes the scene. Voice is not considered at this time."
    messages = [{"role": "user", "content": prompt}]
    return generate(messages, images)

@app.route('/entire_video', methods=['POST'])
def entire_video():
    """
    ì „ì²´ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ ê° ì¥ë©´ë³„ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” API
    ---
    tags:
      - name: ë¹„ë””ì˜¤ ë¶„ì„
        description: ë¹„ë””ì˜¤ ë¶„ì„ ê´€ë ¨ API
    parameters:
      - in: body
        name: body
        required: true
        schema:
          type: object
          properties:
            video_path:
              type: string
              description: ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
    responses:
      200:
        description: ë¹„ë””ì˜¤ ë¶„ì„ ì„±ê³µ
        schema:
          type: object
          properties:
            video_path:
              type: string
            segments:
              type: array
              items:
                type: object
                properties:
                  video_id:
                    type: string
                  video_caption_en:
                    type: string
                  timestamps:
                    type: object
                    properties:
                      start:
                        type: number
                      end:
                        type: number
      400:
        description: ì˜ëª»ëœ ìš”ì²­
      500:
        description: ì„œë²„ ì—ëŸ¬
    """
    try:
        video_path = request.json.get('video_path')
        if not video_path:
            return jsonify({"error: missing video_path"}), 400
        
        video_id = video_path.split('/')[-1].split('.')[0]
        cache_file = os.path.join(CACHE_DIR, f"{video_id}.json")

        if os.path.exists(cache_file):
            with open(cache_file, 'r') as f:
                cached_data = json.load(f)
            return jsonify(cached_data)

        res = []
        scenes = scene_detect(video_path)
        print(scenes)
        for i, (start, end) in enumerate(scenes):
            vframes, _, _ = torchvision.io.read_video(
                filename=video_path, pts_unit='sec', output_format='TCHW', 
                start_pts=start, end_pts=end
            )
            result = predict(vframes)
            res.append({
                'video_id': f"{video_id}_{i}",
                'video_caption_en':result,
                'timestamps':{
                    'start': start,
                    'end': end
                } 
            })
        
        response_data = {
                'video_path':video_path,
                'segments':res
            }
        
        with open(cache_file, 'w') as f:
            json.dump(response_data, f)

        return jsonify(response_data)
    
    except Exception as e:
        return jsonify({'error' : str(e)}), 500

@app.route('/short_video', methods=['POST'])
def short_video():
    """
    íŠ¹ì • êµ¬ê°„ì˜ ë¹„ë””ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ ìº¡ì…˜ì„ ìƒì„±í•˜ëŠ” API
    ---
    tags:
      - name: ë¹„ë””ì˜¤ ë¶„ì„
        description: ë¹„ë””ì˜¤ ë¶„ì„ ê´€ë ¨ API
    parameters:
      - in: body
        name: body
        required: true
        schema:
          type: object
          properties:
            video_path:
              type: string
              description: ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            start:
              type: number
              description: ì‹œì‘ ì‹œê°„(ì´ˆ)
            end:
              type: number
              description: ì¢…ë£Œ ì‹œê°„(ì´ˆ)
    responses:
      200:
        description: ë¹„ë””ì˜¤ ë¶„ì„ ì„±ê³µ
        schema:
          type: object
          properties:
            result:
              type: string
            start:
              type: number
            end:
              type: number
      400:
        description: ì˜ëª»ëœ ìš”ì²­
      500:
        description: ì„œë²„ ì—ëŸ¬
    """
    try:
        video_path = request.json.get('video_path')
        if not video_path:
            return jsonify({"error": 'missing video_path'}), 400
        start = request.json.get('start')
        print(start)
        end = request.json.get('end')
        
        vframes, _, _ = torchvision.io.read_video(
            filename=video_path, pts_unit='sec', output_format='TCHW', 
            start_pts=start, end_pts=end
        )
        
        result = predict(vframes)
        
        return jsonify({'result':result, 'start': start, 'end': end})
    except Exception as e:
        return jsonify({'error' : str(e)}), 500


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.route('/upload_video', methods=['POST'])
def upload_video():
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì €ì¥í•˜ëŠ” API
    """
    try:
        logger.info("ğŸ“¢ íŒŒì¼ ì—…ë¡œë“œ ìš”ì²­ ìˆ˜ì‹ ë¨")

        if 'video' not in request.files:
            logger.error("âŒ ë¹„ë””ì˜¤ íŒŒì¼ì´ ìš”ì²­ì— ì—†ìŒ")
            return jsonify({"error": "ë¹„ë””ì˜¤ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        video_file = request.files['video']
        filename = request.form.get('file_name')
        logger.info(f"ì „ë‹¬ ë°›ì€ filename: ${filename}")
        if video_file.filename == '':
            logger.error("âŒ ì„ íƒëœ íŒŒì¼ì´ ì—†ìŒ")
            return jsonify({"error": "ì„ íƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        logger.info(f"âœ… ì—…ë¡œë“œëœ íŒŒì¼ëª…: {video_file.filename}")

        # ì €ì¥ ë””ë ‰í† ë¦¬ í™•ì¸
        save_dir = '/data/ephemeral/home/new-data/'
        os.makedirs(save_dir, exist_ok=True)

        file_extension = os.path.splitext(video_file.filename)[1]
        
        if not filename:
          logger.info('ì „ë‹¬ë°›ì€ filenameì´ ì—†ìŠµë‹ˆë‹¤.')
          filename = str(get_file_hash(video_file)) + file_extension
        elif not filename.endswith(file_extension):
          filename += file_extension
          
        file_path = os.path.join(save_dir, filename)

        logger.info(f"ğŸ’¾ íŒŒì¼ ì €ì¥ ê²½ë¡œ: {file_path}")

        video_file.seek(0)
        video_file.save(file_path)
        
        file_size = os.path.getsize(file_path)
        if file_size == 0:
          os.remove(file_path)
          return jsonify({"error": "íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì—…ë¡œë“œ í•´ì£¼ì„¸ìš”."})

        logger.info("âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ")

        return jsonify({
            "video_path": file_path,
            "message": "íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤"
        })

    except Exception as e:
        logger.error(f"âŒ íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return jsonify({"error": f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"}), 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=30742)